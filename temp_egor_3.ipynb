{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://amk030.imces.ru/meteodata/AMK_030_BIN/2020/01_2020/01171204.20B',\n",
       " 'http://amk030.imces.ru/meteodata/AMK_030_BIN/2020/01_2020/01171348.20B',\n",
       " 'http://amk030.imces.ru/meteodata/AMK_030_BIN/2020/01_2020/01171531.20B']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import requests,shutil\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os,glob,re\n",
    "from pandas import HDFStore\n",
    "from threading import Thread\n",
    "from datetime import  datetime,timedelta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "#obyazatelnie peremennie (vvedite nije)\n",
    "width = 13\n",
    "base_link =  \"http://amk030.imces.ru/meteodata/AMK_030_BIN/\"\n",
    "start_date = 2020,1,17,12 # nado menyat month to day\n",
    "end_date   = 2020,1,17,16 # nado menyat month to day\n",
    "freq='10min' #выбирайте частота повторения\n",
    "\n",
    "class obrabotka_danniy():\n",
    "    \n",
    "    def __init__(self, base_link=base_link, \n",
    "                  count=10):\n",
    "        self.base_link  = base_link\n",
    "        self.url_count  = count\n",
    "        self.dir_name   = None\n",
    "        self.type_files = None\n",
    "        self.urls       = None\n",
    "        self.file_names = None\n",
    "        \n",
    "        self.start = start_date\n",
    "        self.end   = end_date\n",
    "        self.start_str, self.end_str =['{:02d}'.format(x) for x in self.start] , ['{:02d}'.format(x) for x in self.end]\n",
    "        self.base_link =  \"http://amk030.imces.ru/meteodata/AMK_030_BIN/\"\n",
    "        \n",
    "        self.run_code2()\n",
    "        \n",
    "    def run_code2(self):\n",
    "        \n",
    "        self.urls=self.getfileLinks()\n",
    "        self.create_dir_for_downloading_files()\n",
    "        self.download_files()\n",
    "        self.get_file_names_in_dir()\n",
    "        \n",
    "        \n",
    "    def get_all_links_file(self):\n",
    "        page = requests.get(self.base_link)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        result = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            if (link['href'][-4]=='.' and link['href'][-1]=='B'):\n",
    "                result.append(self.base_link + link['href'])\n",
    "        if len(result)>1:\n",
    "            self.type_files = result[0][-3:]\n",
    "        self.urls = result[:self.url_count]\n",
    "     \n",
    "    def create_dir_for_downloading_files(self):\n",
    "        path = os.path.abspath('') + '\\\\' + str(self.base_link.split('/')[-2])\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "            self.dir_name = path\n",
    "        else:\n",
    "            shutil.rmtree(path)\n",
    "            os.mkdir(path)\n",
    "            self.dir_name = path\n",
    "            \n",
    "     \n",
    "    def download_files(self):\n",
    "        for i,j in enumerate(self.urls):\n",
    "            handle      =   requests.get(self.urls[i])\n",
    "            full_name   =   os.path.join(self.dir_name,os.path.basename(self.urls[i]))\n",
    "            with open(full_name, \"wb\") as f_handler:\n",
    "                chunk = handle.content\n",
    "                f_handler.write(chunk)\n",
    "                    \n",
    "     \n",
    "    def get_file_names_in_dir(self):\n",
    "        file_names  =   []\n",
    "        file_name   =   os.path.join(os.path.abspath(''),self.dir_name,\"*\")\n",
    "        for i in glob.glob(file_name):\n",
    "            file_names.append(i)\n",
    "        self.file_names = file_names\n",
    "        return file_names\n",
    "    \n",
    "    \n",
    "\n",
    "     \n",
    "    def function_obrabotka(self,HDF='data_base.h5'):\n",
    "        width = 13\n",
    "        data_frame_list = []\n",
    "        file_names = self.get_file_names_in_dir()\n",
    "        with pd.HDFStore(HDF,  mode='w') as store:\n",
    "            for i,j in enumerate(file_names):\n",
    "                with open(j, \"rb\") as file:\n",
    "                    content = file.read()\n",
    "                    data_dopolnitelniy = np.frombuffer(content[:17], dtype=np.dtype('i1'))\n",
    "                    data_dopolnitelniy = np.frombuffer(data_dopolnitelniy[:16], dtype=np.dtype('i2'))\n",
    "                    date_temp = data_dopolnitelniy[:-1]\n",
    "                    date_time = datetime(*date_temp).strftime(\"%d.%m.%Y %H:%M:%S\")\n",
    "                    numpy_data_polojitelnie = np.frombuffer(content, dtype=np.dtype('B'))[17:-14]\n",
    "                    numpy_data_polojitelnie = numpy_data_polojitelnie.reshape(int(len(numpy_data_polojitelnie) / width), width)\n",
    "                    numpy_data_polojitelnie = np.delete(numpy_data_polojitelnie,12,1)\n",
    "                    numpy_data_polojitelnie = np.frombuffer(numpy_data_polojitelnie, dtype=np.dtype('i2'))\n",
    "                    numpy_data_polojitelnie = numpy_data_polojitelnie.reshape(int(len(numpy_data_polojitelnie)/6),6)\n",
    "                    row = numpy_data_polojitelnie.shape[0]\n",
    "                    column = numpy_data_polojitelnie.shape[1] + 1\n",
    "                    zero = np.zeros((row,1))\n",
    "                    numpy_data_polojitelnie = np.append(numpy_data_polojitelnie,zero,axis=1) \n",
    "                    for i in range(len(numpy_data_polojitelnie)):\n",
    "                        numpy_data_polojitelnie[i,0] = numpy_data_polojitelnie[i,0] / 100\n",
    "                        numpy_data_polojitelnie[i,1] = numpy_data_polojitelnie[i,1] / 100\n",
    "                        numpy_data_polojitelnie[i,2] = numpy_data_polojitelnie[i,2] / 100\n",
    "                        numpy_data_polojitelnie[i,3] = numpy_data_polojitelnie[i,3] / 100\n",
    "                        numpy_data_polojitelnie[i,4] = numpy_data_polojitelnie[i,4] / 10\n",
    "                        numpy_data_polojitelnie[i,5] = numpy_data_polojitelnie[i,5] / 100\n",
    "                    datelist = pd.date_range(date_time, periods=len(numpy_data_polojitelnie), freq='12.5ms').to_pydatetime()\n",
    "                    data_frame = pd.DataFrame({'Time': datelist, 'Температура': numpy_data_polojitelnie[:,0], 'Южный компонент': numpy_data_polojitelnie[:,1],\n",
    "                                  'Восточный компонент': numpy_data_polojitelnie[:,2], 'Вертикальный компонент': numpy_data_polojitelnie[:,3],\n",
    "                                  'Атмосферное давление': numpy_data_polojitelnie[:,4], 'Влажность воздуха': numpy_data_polojitelnie[:,5],\n",
    "                                  'Признак ошибки': numpy_data_polojitelnie[:,6]})\n",
    "                    data_frame = data_frame.groupby(pd.Grouper(key='Time',freq=freq,sort=True)).mean().round(2)\n",
    "                    data_frame_list.append(data_frame)\n",
    "                    \n",
    "                    store.append('df', data_frame, data_columns= data_frame.columns, format='table')\n",
    "                \n",
    "#         return data_frame_list\n",
    "###############################################################################################\n",
    "        \n",
    "    def getLinks(self,url,directory=None):\n",
    "        result = []\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        if not directory:\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                if (link['href'][-4]=='.' and link['href'][-1]=='B'):\n",
    "                    result.append(link['href'])\n",
    "        else:\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                if (link['href'][-1] == '/'):\n",
    "                    result.append(link['href'])\n",
    "        return result\n",
    "\n",
    "    def getLinksinDir(self):\n",
    "        year_url = os.path.join(base_link,self.start_str[0])   #'http://amk030.imces.ru/meteodata/AMK_030_BIN / +  '2008'\n",
    "        month_urls       = [x for x in self.getLinks(year_url,1) if x[-5:]==self.start_str[0]+'/' and x[0] != '/']\n",
    "        month_year_urls  = [x.split('_') for x in month_urls] #[['01', '2008/'], ['02', '2008/'],\n",
    "        index = None\n",
    "        for i,j in enumerate(month_year_urls):\n",
    "            if self.start_str[0]==month_year_urls[0][-1][:-1] and self.start_str[1]==month_year_urls[i][0]:\n",
    "                if len(month_year_urls[i])==3:\n",
    "                    days_period= [int(x) for x in re.findall(r'\\d+', month_urls[i])]\n",
    "                    if int(self.start_str[1])==(days_period[0]) and  days_period[1] <= int(self.start_str[2]) <= days_period[2]:\n",
    "                        index = i\n",
    "                        break\n",
    "                else: index = i\n",
    "        if index is not None: \n",
    "            self.base_url = year_url +'/'+ month_urls[index]\n",
    "            return self.getLinks(self.base_url)\n",
    "        else: print('no files') \n",
    "            \n",
    "    def getfileLinks(self):\n",
    "        url_files = []\n",
    "        urls =  self.getLinksinDir()\n",
    "        find_from = ''.join(self.start_str[1:])\n",
    "        find_to   = ''.join(  self.end_str[1:])\n",
    "\n",
    "        if urls:\n",
    "            for i in urls:\n",
    "                if int(find_from) <= int(i[:len(find_from)]) < int(find_to):\n",
    "                    url_files.append(self.base_url + i)\n",
    "            if not url_files: print('no files') \n",
    "#             else: return url_files\n",
    "            else: return [url_files[i] for i,j in enumerate(url_files) if not i%10]\n",
    "\n",
    "            \n",
    "obrabotka_danniy=obrabotka_danniy()\n",
    "obrabotka_danniy.urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obrabotka_danniy.urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# тут обрабативаем данные и вес обработанные данные записиваются в \"data_base.h5\"\n",
    "obrabotka_danniy.function_obrabotka()\n",
    "df = pd.read_hdf('data_base.h5')#читаем из базы\n",
    "df.count()#количество значения\n",
    "u_df = df['Южный компонент'].to_numpy()\n",
    "v_df = df['Восточный компонент'].to_numpy()\n",
    "w_df = df['Вертикальный компонент'].to_numpy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "freq = '30min'\n",
    "res = (df.groupby(pd.Grouper(freq=freq,sort=True))['Температура'].mean().reset_index(name='Average'))\n",
    "res.plot(x='Time', y='Average',title='Температура',figsize=(15,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_temp = (df.groupby(pd.Grouper(freq=freq,sort=True))['Температура'].mean().reset_index(name='Average'))\n",
    "res_temp.plot(x='Time', y='Average',title='Температура',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_yujniy = (df.groupby(pd.Grouper(freq=freq,sort=True))['Южный компонент'].mean().reset_index(name='Average'))\n",
    "res_yujniy.plot(x='Time', y='Average',title='Южный компонент',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vostok = (df.groupby(pd.Grouper(freq=freq,sort=True))['Восточный компонент'].mean().reset_index(name='Average'))\n",
    "res_vostok.plot(x='Time', y='Average',title='Восточный компонент',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vertical = (df.groupby(pd.Grouper(freq=freq,sort=True))['Вертикальный компонент'].mean().reset_index(name='Average'))\n",
    "res_vertical.plot(x='Time', y='Average',title='Вертикальный компонент',figsize=(15,4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_davlenie = (df.groupby(pd.Grouper(freq=freq,sort=True))['Атмосферное давление'].mean().reset_index(name='Average'))\n",
    "res_davlenie.plot(x='Time', y='Average',title='Атмосферное давление',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_vlajnost = (df.groupby(pd.Grouper(freq=freq,sort=True))['Влажность воздуха'].mean().reset_index(name='Average'))\n",
    "res_vlajnost.plot(x='Time', y='Average',title='Влажность воздуха',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "df_data = df\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/vortex.csv\")\n",
    "\n",
    "fig = go.Figure(data = go.Cone(\n",
    "    x=df['x'],\n",
    "    y=df['y'],\n",
    "    z=df['z'],\n",
    "    u=df['u'],\n",
    "    v=df['v'],\n",
    "    w=df['w'],\n",
    "    colorscale='Blues',\n",
    "    sizemode=\"absolute\",\n",
    "    sizeref=40))\n",
    "\n",
    "fig.update_layout(scene=dict(aspectratio=dict(x=1, y=1, z=0.8),\n",
    "                             camera_eye=dict(x=1.2, y=1.2, z=0.6)))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    df['u'][i]= u_df[i]\n",
    "    df['v'][i]= v_df[i]\n",
    "    df['w'][i]= w_df[i]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = go.Cone(\n",
    "    x=df['x'],\n",
    "    y=df['y'],\n",
    "    z=df['z'],\n",
    "    u=df['u'],\n",
    "    v=df['v'],\n",
    "    w=df['w'],\n",
    "    colorscale='Blues',\n",
    "    sizemode=\"absolute\",\n",
    "    sizeref=40))\n",
    "\n",
    "fig.update_layout(scene=dict(aspectratio=dict(x=1, y=1, z=0.8),\n",
    "                             camera_eye=dict(x=1.2, y=1.2, z=0.6)))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_temp.plot(x='Time', y='Average',title='Температура_началной',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_value = res_temp['Average'].mean()#получаем среднее значение для температуры\n",
    "res_temp['Average'] = res_temp['Average'].apply(lambda x: x - average_value)#Формулы для вычисления\n",
    "#масштабиремости\n",
    "res_temp.plot(x='Time', y='Average',title='Температура_Масштабирование ',figsize=(15,4))#grafik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os,glob\n",
    "from threading import Thread\n",
    "from datetime import  datetime,timedelta\n",
    "width = 13\n",
    "base_link = \"http://amk030.imces.ru/meteodata/AMK_030_BIN/2019/09_2019/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class obrabotka_danniy(object):\n",
    "#     def __init__(self,urls):\n",
    "#         self.urls = urls\n",
    "     \n",
    "    @staticmethod\n",
    "    def get_all_links_file(base_link=base_link):\n",
    "        page = requests.get(base_link)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        result = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            if (link['href'][-4]=='.' and link['href'][-1]=='B'):\n",
    "                result.append(base_link + link['href'])\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def create_dir_for_downloading_files(self):\n",
    "        path = os.path.abspath('') + '\\\\' + str(urls[0].split('/')[-2])\n",
    "        try:\n",
    "            os.path.isdir(path)\n",
    "            os.mkdir(path)\n",
    "        except FileExistsError as e:\n",
    "            print(e)\n",
    "            \n",
    "    @staticmethod\n",
    "    def download_files(urls=None):\n",
    "        if urls==None:\n",
    "            urls = [\"http://amk030.imces.ru/meteodata/AMK_030_BIN/2019/10_2019/10010008.19B\",\n",
    "                     \"http://amk030.imces.ru/meteodata/AMK_030_BIN/2019/10_2019/10010018.19B\",\n",
    "                       \"http://amk030.imces.ru/meteodata/AMK_030_BIN/2019/06_2019/06010030.19R\"]\n",
    "        for i,j in enumerate(urls):\n",
    "            handle = urllib.request.urlopen(urls[i])\n",
    "            fname = os.path.basename(urls[i])\n",
    "            with open(fname, \"wb\") as f_handler:\n",
    "                while True:\n",
    "                    chunk = handle.read()\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    f_handler.write(chunk)\n",
    "        \n",
    "                    \n",
    "    @staticmethod\n",
    "    def get_file_names_in_dir(self):\n",
    "        \n",
    "        file_names = []\n",
    "        file_name = os.path.abspath('')+'\\\\'\n",
    "        for i in glob.glob(\"*.19B\"):\n",
    "            file_names.append(file_name + i)\n",
    "        return file_names\n",
    "    \n",
    "    @staticmethod\n",
    "    def function_obrabotka(default=0):\n",
    "        data_frame_list = []\n",
    "        file_names = os.path.abspath('')+'\\\\' + glob.glob(\"*.19B\")[0]\n",
    "        if default==1:\n",
    "            file_names = get_file_names_in_dir()\n",
    "        file_names = get_file_names_in_dir()\n",
    "        for i,j in enumerate(file_names):\n",
    "            with open(j, \"rb\") as file:\n",
    "                content = file.read()\n",
    "                data_dopolnitelniy = np.frombuffer(content[:17], dtype=np.dtype('i1'))\n",
    "                data_dopolnitelniy = np.frombuffer(data_dopolnitelniy[:16], dtype=np.dtype('i2'))\n",
    "                date_temp = data_dopolnitelniy[:-1]\n",
    "                date_time = datetime(*date_temp).strftime(\"%d.%m.%Y %H:%M:%S.%f\")\n",
    "                numpy_data_polojitelnie = np.frombuffer(content, dtype=np.dtype('B'))[17:-14]\n",
    "                numpy_data_polojitelnie = numpy_data_polojitelnie.reshape(int(len(numpy_data_polojitelnie) / width), width)\n",
    "                numpy_data_polojitelnie = np.delete(numpy_data_polojitelnie,12,1)\n",
    "                numpy_data_polojitelnie = np.frombuffer(numpy_data_polojitelnie, dtype=np.dtype('i2'))\n",
    "                numpy_data_polojitelnie = numpy_data_polojitelnie.reshape(int(len(numpy_data_polojitelnie)/6),6)\n",
    "                row = numpy_data_polojitelnie.shape[0]\n",
    "                column = numpy_data_polojitelnie.shape[1] + 1\n",
    "                zero = np.zeros((row,1))\n",
    "                numpy_data_polojitelnie = np.append(numpy_data_polojitelnie,zero,axis=1) \n",
    "                for i in range(len(numpy_data_polojitelnie)):\n",
    "                    numpy_data_polojitelnie[i,0] = numpy_data_polojitelnie[i,0] / 100\n",
    "                    numpy_data_polojitelnie[i,1] = numpy_data_polojitelnie[i,1] / 100\n",
    "                    numpy_data_polojitelnie[i,2] = numpy_data_polojitelnie[i,2] / 100\n",
    "                    numpy_data_polojitelnie[i,3] = numpy_data_polojitelnie[i,3] / 100\n",
    "                    numpy_data_polojitelnie[i,4] = numpy_data_polojitelnie[i,4] / 10\n",
    "                    numpy_data_polojitelnie[i,5] = numpy_data_polojitelnie[i,5] / 100\n",
    "                datelist = pd.date_range(date_time, periods=len(numpy_data_polojitelnie), freq='12.5ms').to_pydatetime()\n",
    "                data_frame = pd.DataFrame({'Time': datelist, 'Температура': numpy_data_polojitelnie[:,0], 'Южный компонент': numpy_data_polojitelnie[:,1],\n",
    "                              'Восточный компонент': numpy_data_polojitelnie[:,2], 'Вертикальный компонент': numpy_data_polojitelnie[:,3],\n",
    "                              'Атмосферное давление': numpy_data_polojitelnie[:,4], 'Влажность воздуха': numpy_data_polojitelnie[:,5],\n",
    "                              'Признак ошибки': numpy_data_polojitelnie[:,6]})\n",
    "                data_frame_list.append(data_frame)\n",
    "        return data_frame_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = obrabotka_danniy.download_files\n",
    "links_files = obrabotka_danniy().get_all_links_file()\n",
    "cut_links_files = [[links_files[:1000]],\n",
    "                   [links_files[1000:2000]],\n",
    "                   [links_files[2000:3000]],\n",
    "                   [links_files[3000:]]]\n",
    "cut_links_files = cut_links_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(cut_links_files):\n",
    "    my_thread = Thread(target=func, name=[i], args=(j,))\n",
    "    my_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwe():\n",
    "    asd = obrabotka_danniy.function_obrabotka()\n",
    "    asdf = pd.concat(asd)\n",
    "    print(len(asdf))\n",
    "    return asdf\n",
    "asd = qwe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
